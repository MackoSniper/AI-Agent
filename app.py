import streamlit as st # type: ignore[import]
import os
import time
from dotenv import load_dotenv # type: ignore[import]
from google import genai
from google.genai import types # type: ignore[import]
from PIL import Image # type: ignore[import]
import io
import base64
from streamlit_mic_recorder import mic_recorder # type: ignore[import]


# Importujemy nasze modu≈Çy
from call_function import available_functions_tool, call_function
from prompts import system_prompt
from reviewer import review_code
from memory import load_memory, save_memory, clear_memory

# Konfiguracja strony
st.set_page_config(page_title="AI Agent Workspace", page_icon="ü§ñ", layout="wide")

# ≈Åadowanie zmiennych
load_dotenv()
api_key = os.environ.get("GEMINI_API_KEY")

# Funkcje wra≈ºliwe wymagajƒÖce zgody
SENSITIVE_FUNCTIONS = ["write_file", "run_python_file"]

# === INICJALIZACJA STANU (SESSION STATE) ===
if "messages" not in st.session_state:
    st.session_state.messages = load_memory()  # ≈Åadujemy pamiƒôƒá z pliku na start

if "client" not in st.session_state:
    st.session_state.client = genai.Client(api_key=api_key)

# === UI: PASEK BOCZNY ===
with st.sidebar:
    st.title("üîß Panel Sterowania")
    if st.button("üßπ Wyczy≈õƒá pamiƒôƒá"):
        clear_memory()
        st.session_state.messages = []
        st.rerun()
    
    st.markdown("---")
    st.markdown("**Aktywne modu≈Çy:**")
    st.success("‚úÖ Dynamic Loader")
    st.success("‚úÖ Code Reviewer")
    st.success("‚úÖ Long-term Memory")
    st.success("‚úÖ Internet Access")
    st.success("‚úÖ Docker Sandbox")

    # --- OCZY AGENTA ---
    st.markdown("---")
    st.subheader("üì∏ Oczy Agenta")
    uploaded_file = st.file_uploader(
        "Poka≈º obraz (Screenshot/Foto)", 
        type=["png", "jpg", "jpeg", "webp"],
        key="vision_input"
    )
    
    image_input = None
    if uploaded_file:
        image_input = Image.open(uploaded_file)
        st.image(image_input, caption="Obraz do wys≈Çania", width=True)

    
    # --- US≈ÅUGA AUDIO (MIKROFON) ---
    st.markdown("---")
    st.subheader("üé§ Uszy Agenta")

    # Komponent nagrywajƒÖcy
    audio_input = mic_recorder(
        start_prompt="üî¥ Nagraj",
        stop_prompt="‚èπÔ∏è Stop",
        just_once=True,
        key='recorder'
    )

# === UI: G≈Å√ìWNE OKNO CZATU ===
st.title("ü§ñ AI Super-Agent")
st.caption("Powered by Gemini 2.5 Flash & Python")

# Wy≈õwietlanie historii czatu
for msg in st.session_state.messages:
    if msg.role == "user":
        with st.chat_message("user"):
            st.markdown(msg.parts[0].text)
            # Je≈õli u≈ºytkownik wys≈Ça≈Ç obrazek w poprzednich turach, tu by≈õmy musieli go odtworzyƒá,
            # ale w tej prostej wersji pomijamy wy≈õwietlanie starych obrazk√≥w usera dla czytelno≈õci.
            
    elif msg.role == "model":
        text_content = ""
        for part in msg.parts:
            if part.text:
                text_content += part.text
        if text_content:
            with st.chat_message("assistant"):
                st.markdown(text_content)
    
    # === NOWO≈öƒÜ: Wy≈õwietlanie wykres√≥w stworzonych przez Agenta ===
    elif msg.role == "tool":
        # Sprawdzamy, czy narzƒôdzie zwr√≥ci≈Ço informacjƒô o stworzonym pliku graficznym
        for part in msg.parts:
            if part.function_response and part.function_response.response:
                resp = str(part.function_response.response)
                # Prosta heurystyka: je≈õli odpowied≈∫ zawiera ".png" lub ".jpg"
                if ".png" in resp or ".jpg" in resp:
                    import glob
                    # Szukamy najnowszego pliku w workspace
                    files = glob.glob("agent_workspace/*.png") + glob.glob("agent_workspace/*.jpg")
                    if files:
                        latest_file = max(files, key=os.path.getmtime)
                        # Je≈õli plik jest ≈õwie≈ºy (z tej sesji)
                        with st.chat_message("assistant"):
                            st.image(latest_file, caption="Wygenerowany plik", width=400)

# === LOGIKA AGENTA ===

# 1. Pobieramy input tekstowy
prompt_text = st.chat_input("O co chcesz zapytaƒá?")

# 2. Sprawdzamy, co zrobi≈Ç u≈ºytkownik (Napisa≈Ç czy Nagra≈Ç?)
user_action = None

if prompt_text:
    user_action = "text"
elif audio_input:
    user_action = "audio"

# Je≈õli jest jakakolwiek akcja (Tekst lub Audio)
if user_action:
    user_parts = []
    
    # --- SCENARIUSZ A: TEKST ---
    if user_action == "text":
        user_parts.append(types.Part(text=prompt_text))
        # Wy≈õwietl w czacie
        with st.chat_message("user"):
            st.markdown(prompt_text)

    # --- SCENARIUSZ B: AUDIO (G≈ÅOS) ---
    elif user_action == "audio":
        # WyciƒÖgamy bajty z nagrania
        audio_bytes = audio_input['bytes']
        
        # Dodajemy plik audio dla modelu
        user_parts.append(types.Part.from_bytes(data=audio_bytes, mime_type="audio/wav"))
        # Dodajemy instrukcjƒô pomocniczƒÖ
        user_parts.append(types.Part(text="Ods≈Çuchaj to nagranie i wykonaj polecenie."))
        
        # Wy≈õwietl odtwarzacz w czacie (≈ºeby≈õ widzia≈Ç, ≈ºe wysz≈Ço)
        with st.chat_message("user"):
            st.audio(audio_bytes, format="audio/wav")
            st.caption("üéôÔ∏è Wiadomo≈õƒá g≈Çosowa")

    # --- WSP√ìLNE: OBRAZ (Je≈õli dodano w pasku bocznym) ---
    if image_input:
        img_byte_arr = io.BytesIO()
        image_input.save(img_byte_arr, format=image_input.format)
        img_bytes = img_byte_arr.getvalue()
        
        user_parts.append(
            types.Part.from_bytes(data=img_bytes, mime_type=f"image/{image_input.format.lower()}")
        )
        # Poka≈º obrazek w czacie
        with st.chat_message("user"):
            st.image(image_input, width=200)

    # 3. Zapisz w historii
    st.session_state.messages.append(types.Content(role="user", parts=user_parts))

    # 4. Uruchom Agenta
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        status_container = st.status("Thinking...", expanded=True)
        
        current_messages = st.session_state.messages.copy()
        MAX_ITERS = 20
        
        try:
            for i in range(MAX_ITERS):
                status_container.write(f"üîÑ Iteracja {i+1}...")
                
                # Wywo≈Çanie API Gemini
                response = st.session_state.client.models.generate_content(
                    model="gemini-2.5-flash", # Upewnij siƒô, ≈ºe masz tu dobry model (np. 2.0 Flash)
                    contents=current_messages,
                    config=types.GenerateContentConfig(
                        tools=[available_functions_tool],
                        system_instruction=system_prompt
                    ),
                )

                # Dodajemy odpowied≈∫ kandydata do historii (tymczasowej)
                if response.candidates and response.candidates[0].content:
                    current_messages.append(response.candidates[0].content)

                # Sprawdzamy czy agent chce zako≈Ñczyƒá (brak wywo≈Ça≈Ñ funkcji)
                if not response.function_calls:
                    status_container.update(label="Gotowe!", state="complete", expanded=False)
                    message_placeholder.markdown(response.text)
                    
                    # Aktualizujemy g≈Ç√≥wnƒÖ pamiƒôƒá sesji
                    st.session_state.messages = current_messages
                    save_memory(st.session_state.messages)
                    break
                
                # Je≈õli sƒÖ funkcje do wykonania:
                function_responses = []
                
                for function_call in response.function_calls:
                    func_name = function_call.name
                    func_args = function_call.args
                    
                    status_container.write(f"üõ†Ô∏è Agent chce u≈ºyƒá: `{func_name}`")
                    
                    # --- REVIEWER ---
                    if func_name == "write_file":
                        file_path = func_args.get("file_path", "")
                        if file_path.endswith(".py"):
                            status_container.info(f"üîç Reviewer sprawdza kod: {file_path}")
                            content_to_review = func_args.get("content", "")
                            is_approved, feedback = review_code(content_to_review)
                            
                            if not is_approved:
                                status_container.error(f"‚ùå Reviewer odrzuci≈Ç kod: {feedback}")
                                rejection_part = types.Part.from_function_response(
                                    name=func_name,
                                    response={"error": f"Security Review Failed: {feedback}"}
                                )
                                function_responses.append(rejection_part)
                                continue 
                            else:
                                status_container.success("‚úÖ Reviewer zatwierdzi≈Ç kod.")

                    # --- HUMAN APPROVAL (Symulacja) ---
                    if func_name in SENSITIVE_FUNCTIONS:
                            status_container.warning(f"‚ö†Ô∏è Wykonujƒô wra≈ºliwƒÖ akcjƒô: {func_name}...")
                            time.sleep(1)

                    # --- WYKONANIE ---
                    result = call_function(function_call, verbose=True)
                    
                    # Wy≈õwietl wynik w expanderze
                    result_text = str(result.parts[0].function_response.response)[:200] + "..."
                    status_container.code(f"Wynik: {result_text}")
                    
                    function_responses.append(result.parts[0])

                # Dodajemy wyniki funkcji do historii
                current_messages.append(types.Content(role="tool", parts=function_responses))
                
        except Exception as e:
            st.error(f"B≈ÇƒÖd krytyczny: {e}")